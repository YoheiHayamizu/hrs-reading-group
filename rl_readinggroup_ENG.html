<!doctype html>
<html lang="zh-CN">
    <head>
        <meta charset="ansi">
	<meta name="description" content="this is a website">
        <meta name="keywords" content="website,html,css">

        <title>ReadingGroup</title>

        <link rel="stylesheet" style="text/css" href="index.css">

    </head>
    <body>
        <div id="head">
            <div class="logo_title">
                <h1><font face="verdana" color="#0000FF">Reinforcement Learning Reading Group</font></h1>
                <!---<h2><font face="verdana" color="#4169E1">Good papers &amp; Interesting ideas &amp; Delicisous pizzas!</font></h2>-->
          </div>

            <!--<div class="naviBar">
                <ul>
                    <li><a href=""><font face="verdana" color="green">首页</font></a></li>
                    <li><a href=""><font face="verdana" color="green">闲言碎语</font></a></li>
                    <li><a href=""><font face="verdana" color="green">我是谁</font></a></li>
                </ul>
            </div>-->
            <div class="clearfloat"></div>
        </div>

        <div id="wrapper">
            <div class="main">

<div class="item">
                    <div class="item_image">
                        <img src="rl.png" alt="this is a contentImage">
                    </div>
                    <div class="item_content">
                        <h3><font face="verdana" color="black" size="5">Upcomming!</font></h3>
						<h3><a href="https://arxiv.org/pdf/1707.06347.pdf"><font face="verdana" color="black" size="3">Proximal Policy Optimization Algorithms <font face="verdana" color="black" size="0.5">(click it !)</font> </font></a></h3>
                        <p class="item_info"><font face="verdana" color="black" size="2.5">Authors: John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov</font></p>
                        <p class="item_info"><font face="verdana" color="black" size="2.5">Leader: Nicholas A Abate</font></p>
                        <p class="item_info"><font face="verdana" color="black" size="2.5">Venue: Online</font></p>
                        <p class="item_info"><font face="verdana" color="black" size="2.5">Date: 12-1 p.m. June 4th, 2020</font></p>
                        <p class="item_info"><a href="https://binghamton.zoom.us/j/3929288199"><font face="verdana" color="red" size="3">Join Zoom Meeting: https://binghamton.zoom.us/j/3929288199</font></a></p>
                        <p class="item_descri"><font face="verdana" color="black" size="2.5">Abstract: We propose a new family of policy gradient methods for reinforcement learning, which al-
ternate between sampling data through interaction with the environment, and optimizing a
“surrogate” objective function using stochastic gradient ascent. Whereas standard policy gra-
dient methods perform one gradient update per data sample, we propose a novel objective
function that enables multiple epochs of minibatch updates. The new methods, which we call
proximal policy optimization (PPO), have some of the benefits of trust region policy optimiza-
tion (TRPO), but they are much simpler to implement, more general, and have better sample
complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, includ-
ing simulated robotic locomotion and Atari game playing, and we show that PPO outperforms
other online policy gradient methods, and overall strikes a favorable balance between sample
complexity, simplicity, and wall-time.</font></p>
                    </div>
                </div>

            </div>

            <div class="side">
                <div class="author_info">
                    <!--<div class="author_Image">
                        <img src="rl.png" alt="this is a author image">
                    </div>-->

                    <div class="author_descri">
                        <h4><font face="verdana" color="black" size="4">About Reading Group</font></h4>
                        <p align="center">
							<font face="verdana" color="black" size="2.8">The reading group is held to learn Reinforcement Learning. In the initial phase, we will watch teaching videos
                                related to RL published by Dr. Bolei Zhou, and then discuss the context presented in the video together to share experience and solve puzzles. This phase will last up to three months. </font>
					    </p>
                    </div>
                </div>

				<div class="top_article">
                    <h3><font face="verdana" color="black" size="4">How to join?</font></h3>
                    <ul>
                        <li><font face="verdana" color="black" size="2.8">Contacts: <U>Yan Ding</U></font></li>
						<li><font face="verdana" color="black" size="2.8">Email: <U>yding25@binghamton.edu</U></font>
						<li><font face="verdana" color="black" size="2.8">Homepage: <a href="https://yding25.github.io"><U><font face="verdana" color="black" size="2.8">yding25.github.io</font></U></a> </font></li>
                    </ul>
                </div>

                <div class="top_article">
                    <h3><font face="verdana" color="black" size="4">Reinforcement Learning</font></h3>
                    <ul>
                        <li><font face="verdana" color="black" size="2.8">This is a reading group, where students watch teaching videos related to RL published by  <a href="https://www.ie.cuhk.edu.hk/people/blzhou.shtml">Dr. Bolei Zhou.</a>
                        </font></li>
                    </ul>
                </div>

                <!---
                <div class="top_article">
                    <h3><font face="verdana" color="black" size="4">Recommended Papers</font></h3>
                    <ul>
                        <li><font face="verdana" color="black" size="2.8">Paper-1: Proximal Policy Optimization Algorithms</font></li>
                        <li><font face="verdana" color="black" size="2.8">Paper-2: Imagination-Augmented Agents for Deep Reinforcement Learning</font></li>
                        <li><font face="verdana" color="black" size="2.8">Paper-3</font></li>
                        <li><font face="verdana" color="black" size="2.8">Paper-4</font></li>
                        <li><font face="verdana" color="black" size="2.8">Paper-5</font></li>
                        <li><font face="verdana" color="black" size="2.8">Paper-6</font></li>
                    </ul>
                </div>-->

                 <div class="site_info">
                    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></p>
                    <span id="busuanzi_container_site_pv" >| totalview: <span id="busuanzi_value_site_pv"></span>  </span>
                    <span id="busuanzi_container_site_uv" >| visitors: <span id="busuanzi_value_site_uv"></span>  </span>
                </div>

            </div>

            <div class="clearfloat"></div>
        </div>

        <div id="footer">
            <div class="copyRight">
              <p>2016-2050 CopyRight website Demo Site</p>
            </div>

            <div class="site_link">
                <ul>
                    <li><a href="">关于我们</a></li>
                    <li><a href="">联系我们</a></li>
                    <li><a href="">使用条款</a></li>
                    <li><a href="">意见反馈</a></li>
                <ul>
            </div>
        </div>

    </body>
</html>
